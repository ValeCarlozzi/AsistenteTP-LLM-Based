{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCUMa9koNNbj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\valec\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# --- CELDA 1: Dependencias y librerías ---\n",
        "import os\n",
        "import requests\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m_GQvkCnNNbk"
      },
      "outputs": [],
      "source": [
        "# ---- CELDA 2: Tu API KEY segura (NO subas a github ni la compartas)\n",
        "# Reemplazá por tu key real, o lee de una variable segura/entorno\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VL7I6Hd5NNbk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\valec\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\valec\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        }
      ],
      "source": [
        "# ---- CELDA 3: Creá corpus y embeddings ----\n",
        "corpus = [\n",
        "    \"La ley nacional de tránsito establece que el uso de casco es obligatorio en motocicletas en Argentina.\",\n",
        "    \"El salario mínimo en Argentina en junio de 2024 es de 234,315 pesos según el Boletín Oficial.\",\n",
        "    \"Para recuperar una contraseña en el sistema universitario, se debe acceder a la opción 'Olvidé mi contraseña' y seguir los pasos.\",\n",
        "    \"El error estándar se calcula como la raíz cuadrada de la varianza sobre el tamaño de la muestra.\",\n",
        "    \"El aprendizaje profundo ha revolucionado el diagnóstico médico por imágenes.\",\n",
        "    \"La inscripción a materias en la facultad cierra generalmente a mediados de marzo y agosto.\",\n",
        "]\n",
        "\n",
        "EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "tokenizer_emb = AutoTokenizer.from_pretrained(EMBEDDING_MODEL)\n",
        "model_emb = AutoModel.from_pretrained(EMBEDDING_MODEL)\n",
        "\n",
        "def compute_embedding(text):\n",
        "    encoded_input = tokenizer_emb(text, padding=True, truncation=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        model_output = model_emb(**encoded_input)\n",
        "    embeddings = model_output.last_hidden_state\n",
        "    mask = encoded_input['attention_mask'].unsqueeze(-1).expand(embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(embeddings * mask, 1)\n",
        "    sum_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
        "    return (sum_embeddings / sum_mask).squeeze().numpy()\n",
        "\n",
        "chunk_embeddings = np.vstack([compute_embedding(ch) for ch in corpus])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz04yyZxNNbk",
        "outputId": "a0bfa01c-f40e-42c2-96b1-4940ff9cf0d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunks recuperados:\n",
            "El salario mínimo en Argentina en junio de 2024 es de 234,315 pesos según el Boletín Oficial.\n",
            "(Similitud: 0.76)\n",
            "\n",
            "El error estándar se calcula como la raíz cuadrada de la varianza sobre el tamaño de la muestra.\n",
            "(Similitud: 0.51)\n",
            "\n",
            "La ley nacional de tránsito establece que el uso de casco es obligatorio en motocicletas en Argentina.\n",
            "(Similitud: 0.49)\n",
            "\n",
            "\n",
            "=== Prompt para LLM via Groq ===\n",
            "\n",
            "Contexto:\n",
            "El salario mínimo en Argentina en junio de 2024 es de 234,315 pesos según el Boletín Oficial.\n",
            "El error estándar se calcula como la raíz cuadrada de la varianza sobre el tamaño de la muestra.\n",
            "La ley nacional de tránsito establece que el uso de casco es obligatorio en motocicletas en Argentina.\n",
            "---\n",
            "Pregunta: ¿Cuánto es el salario mínimo actual en Argentina?\n",
            "Respondé de forma precisa y citando la evidencia textual relevante cuando corresponda. Si el contexto no contiene la respuesta, indicá 'No disponible en los textos recuperados'.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ---- CELDA 4: Definí tu pregunta y hacé retrieval semántico ----\n",
        "query = \"¿Cuánto es el salario mínimo actual en Argentina?\"\n",
        "query_emb = compute_embedding(query)\n",
        "sims = cosine_similarity([query_emb], chunk_embeddings)[0]\n",
        "top_indexes = sims.argsort()[-3:][::-1]  # Top 3 relevantes\n",
        "\n",
        "print(\"Chunks recuperados:\")\n",
        "for i in top_indexes:\n",
        "    print(f\"{corpus[i]}\\n(Similitud: {sims[i]:.2f})\\n\")\n",
        "\n",
        "context = \"\\n\".join([corpus[i] for i in top_indexes])\n",
        "prompt = f\"\"\"Contexto:\n",
        "{context}\n",
        "---\n",
        "Pregunta: {query}\n",
        "Respondé de forma precisa y citando la evidencia textual relevante cuando corresponda. Si el contexto no contiene la respuesta, indicá 'No disponible en los textos recuperados'.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n=== Prompt para LLM via Groq ===\\n\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9nhp59tBNNbl"
      },
      "outputs": [],
      "source": [
        "# ---- CELDA 5: Llama 3 via Groq API ----\n",
        "def groq_llm(prompt,\n",
        "             model=\"llama3-70b-8192\", # o llama3-8b-8192 según disponibilidad\n",
        "             max_tokens=250, temperature=0.1,\n",
        "             system_message=\"Sos un asistente experto en IA. Respondé en español.\"):\n",
        "    api_url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {os.environ['GROQ_API_KEY']}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"temperature\": temperature,\n",
        "        \"stop\": None\n",
        "    }\n",
        "    response = requests.post(api_url, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        print(response.text)\n",
        "        raise Exception(\"Error en la API de Groq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5spsWPaMNNbl",
        "outputId": "608d066e-623d-4599-c145-b9cce14d507c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Respuesta Llama 3 (Groq) ===\n",
            "\n",
            "Según el contexto, el salario mínimo actual en Argentina es de 234,315 pesos, según el Boletín Oficial.\n"
          ]
        }
      ],
      "source": [
        "# ---- CELDA 6: Ejecutar el LLM sobre tu prompt RAG ----\n",
        "respuesta = groq_llm(prompt)\n",
        "print(\"\\n=== Respuesta Llama 3 (Groq) ===\\n\")\n",
        "print(respuesta)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
